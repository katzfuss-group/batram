{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This is a the shrinkage version of Transport map. In this version, \n",
    "the regression functions $f_i$ and the niggest parameters $d_i$ are \n",
    "assumed to have some specific structures. These values are given by\n",
    "the parametric covariance matrix. Unlike the example in other notebook,\n",
    "here we try to estimate the parametric covariance matrix parameters \n",
    "using the integrated log-likelihood function.\n",
    "\n",
    "\n",
    "Author: Anirban Chakraborty,\n",
    "Last modified: May 13, 2024\n",
    "\"\"\"\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from veccs import orderings\n",
    "from gpytorch.kernels import MaternKernel\n",
    "from sklearn.gaussian_process import kernels\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from batram.helpers import make_grid, GaussianProcessGenerator\n",
    "from batram.legmods import Data, SimpleTM\n",
    "from batram.shrinkmods import ShrinkTM, EstimableShrinkTM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing log-score with the base transport maps (exponential kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(20240522)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## kernel and location parameters\n",
    "\n",
    "num_locs = 30; dim_locs = 2\n",
    "nu_original = 0.5\n",
    "length_scale_original = 0.3\n",
    "numSamples = 30\n",
    "sd_noise=1e-6\n",
    "largest_conditioning_set = 30\n",
    "sigmasq_f = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"../data/NR900ExpLST30SIGSQT10.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "locs = data[\"locs\"]\n",
    "locsorder = data[\"order\"]\n",
    "gp = data[\"gp\"]\n",
    "torchdata = data[\"data\"][:, locsorder]\n",
    "nn = orderings.find_nns_l2(locs, largest_conditioning_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## getting the data ready\n",
    "\n",
    "numSamples = [1, 2, 5, 10, 15, 20, 30, 50, 80, 160, 200]\n",
    "neglogScore_tm = torch.zeros(len(numSamples))\n",
    "neglogScore_shrink = torch.zeros(len(numSamples))\n",
    "tm_models = []\n",
    "shrink_models = []\n",
    "yreps = 50 #to be used for estimating log-score\n",
    "nsteps = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fit models\n",
    "for i, n in enumerate(numSamples):\n",
    "    obs = torchdata[0:n, :] #snip first n samples\n",
    "    #if obs.dim() == 1:\n",
    "    #    obs = obs.unsqueeze(0)\n",
    "    obsTrain = obs\n",
    "\n",
    "    # Create a `Data` object for use with the `SimpleTM`/ `ShrinkTM` model.\n",
    "    data_tm = Data.new(torch.as_tensor(locs).float(), obs, torch.as_tensor(nn))\n",
    "    data_shrink = Data.new(torch.as_tensor(locs).float(), obs, torch.as_tensor(nn))\n",
    "\n",
    "    tm = SimpleTM(data_tm, theta_init=None, linear=False, smooth=1.5, nug_mult=4.0)\n",
    "    opt = torch.optim.Adam(tm.parameters(), lr=0.01)\n",
    "    sched = torch.optim.lr_scheduler.CosineAnnealingLR(opt, nsteps)\n",
    "    res = tm.fit(\n",
    "        nsteps, 0.1, test_data=tm.data, optimizer=opt, scheduler=sched, batch_size=300\n",
    "    )\n",
    "    tm_models.append(tm)\n",
    "    \n",
    "    shrink_tm = EstimableShrinkTM(data=data_shrink, linear=False, \n",
    "                     transportmap_smooth=1.5, \n",
    "                     parametric_kernel= \"exponential\",\n",
    "                     param_nu=0.5,\n",
    "                     param_ls=1.0,\n",
    "                     nug_mult_bounded=False)\n",
    "    opt2 = torch.optim.Adam(shrink_tm.parameters(), lr=0.01)\n",
    "    sched2 = torch.optim.lr_scheduler.CosineAnnealingLR(opt2, nsteps)\n",
    "    res2 = shrink_tm.fit(\n",
    "        nsteps, 0.1, test_data=shrink_tm.data, optimizer=opt2, scheduler=sched2, batch_size=300,\n",
    "\n",
    "    )\n",
    "    shrink_models.append(shrink_tm)\n",
    "\n",
    "    for _j in range(0, 50):\n",
    "        with torch.no_grad():\n",
    "            neglogScore_tm[i] += tm.score(torchdata[(200 + _j), :])\n",
    "        neglogScore_shrink[i] += shrink_tm.score(torchdata[(200 + _j), :])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(shrink_models)):\n",
    "    with torch.no_grad():\n",
    "        print(shrink_models[i].parametric_kernel.log_sigmasq.exp().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(shrink_models)):\n",
    "    with torch.no_grad():\n",
    "        print(shrink_models[i].parametric_kernel.log_ls.exp().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(shrink_models)):\n",
    "    with torch.no_grad():\n",
    "        print(shrink_models[i].transform_shrinkage_factor().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logScore_tm = neglogScore_tm/50\n",
    "logScore_shrink = neglogScore_shrink/50\n",
    "plt.plot(torch.arange(len(numSamples)), logScore_tm)\n",
    "plt.plot(torch.arange(len(numSamples)), logScore_shrink)\n",
    "plt.ylim(torch.concatenate((logScore_tm, logScore_shrink)).min() - 50, \n",
    "         torch.concatenate((logScore_tm, logScore_shrink)).max() + 50)\n",
    "plt.title(\"Log-Score of SimpleTM and ShrinkTM\")\n",
    "plt.xticks(torch.arange(len(numSamples)), labels = numSamples);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(torch.arange(len(numSamples)), logScore_shrink)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    \"gp_generator\": gp,\n",
    "    \"tm_models\": tm_models,\n",
    "    \"shrink_models\": shrink_models,\n",
    "    \"tm_logscore\" : logScore_tm,\n",
    "    \"shrink_logscore\": logScore_shrink,\n",
    "    \"numSamples\": numSamples\n",
    "}, f\"../results/modelsNR_LST{int(100*length_scale_original)}_SQT{int(100*sigmasq_f)}.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Climate data application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anirban0451/miniconda3/envs/shrink2param/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from veccs import orderings\n",
    "from gpytorch.kernels import MaternKernel\n",
    "from sklearn.gaussian_process import kernels\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from batram.helpers import make_grid, GaussianProcessGenerator\n",
    "from batram.legmods import Data, SimpleTM\n",
    "from batram.shrinkmods import ShrinkTM, EstimableShrinkTM\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"../data/prec_days.pkl\", \"rb\") as f:\n",
    "    prec_days = pickle.load(f)\n",
    "\n",
    "#with open(\"../data/prec_all.pkl\", \"rb\") as f:\n",
    "#    prec_all = pickle.load(f)\n",
    "\n",
    "#lat = prec_days[\"lat\"]\n",
    "#lon = prec_days[\"lon\"]\n",
    "#obs = np.log(prec_days[\"precs\"][:,:,0].T + 1e-10)\n",
    "locs = np.loadtxt(\"../data/locs.csv\", skiprows=1, delimiter=\",\")\n",
    "lat = locs[:, 1]\n",
    "lon = locs[:, 0]\n",
    "obs = np.loadtxt(\"../data/prec-june1.csv\", skiprows=1, delimiter=\",\").T\n",
    "#l=lon/360*2*math.pi; L=lat/360*2*math.pi\n",
    "#locs = (np.vstack([np.cos(L)*np.cos(l),np.cos(L)*np.sin(l),np.sin(L)])).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99488488, 0.99488488, 0.99488488, ..., 0.99488488, 0.99488488,\n",
       "        0.99488488]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#obs_mean = obs.mean(axis = 0, keepdims = True)\n",
    "obs.mean(axis = 0, keepdims = True)\n",
    "obs.std(axis = 0, keepdims = True)\n",
    "#obs_sd = obs.std(axis = 0, keepdims = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#obs_scaled = (obs - obs_mean)/obs_sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "locsorder = orderings.maxmin_cpp(locs)\n",
    "locsTrain = locs[locsorder, :]\n",
    "nn = orderings.find_nns_l2(locs, 30)\n",
    "shuffle = torch.randperm(obs.shape[0])\n",
    "\n",
    "obsTrain = torch.from_numpy((obs[shuffle,:])[:, locsorder]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsteps = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to compute Cholesky decomposition of G.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_LinAlgError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m/mnt/c/PhDResearch/Self/parametricshrinkage/batram-shrink2param/src/batram/legmods.py:369\u001b[0m, in \u001b[0;36mTransportMapKernel.forward\u001b[0;34m(self, data, nug_mean)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 369\u001b[0m     g_chol \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mcholesky(g)\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    371\u001b[0m     \u001b[38;5;66;03m# One contrast between the errors we return here and the ones in the\u001b[39;00m\n\u001b[1;32m    372\u001b[0m     \u001b[38;5;66;03m# other function is that here we don't know which Cholesky factor\u001b[39;00m\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;66;03m# failed based on this message. It would be good to inherit the\u001b[39;00m\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;66;03m# torch.linalg.LinAlgError and make a more informative error message\u001b[39;00m\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;66;03m# with it.\u001b[39;00m\n",
      "\u001b[0;31m_LinAlgError\u001b[0m: linalg.cholesky: (Batch element 1769): The factorization could not be completed because the input is not positive-definite (the leading minor of order 1 is not positive-definite).",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m opt \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(tm\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m      5\u001b[0m sched \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mCosineAnnealingLR(opt, nsteps)\n\u001b[0;32m----> 6\u001b[0m res \u001b[38;5;241m=\u001b[39m tm\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m      7\u001b[0m     nsteps, \u001b[38;5;241m0.1\u001b[39m, test_data\u001b[38;5;241m=\u001b[39mtm\u001b[38;5;241m.\u001b[39mdata, optimizer\u001b[38;5;241m=\u001b[39mopt, scheduler\u001b[38;5;241m=\u001b[39msched, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m900\u001b[39m\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m     10\u001b[0m shrink_tm \u001b[38;5;241m=\u001b[39m EstimableShrinkTM(data\u001b[38;5;241m=\u001b[39mdata, linear\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \n\u001b[1;32m     11\u001b[0m                     transportmap_smooth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.5\u001b[39m, \n\u001b[1;32m     12\u001b[0m                     parametric_kernel\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexponential\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     13\u001b[0m                     param_nu\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m,\n\u001b[1;32m     14\u001b[0m                     param_ls\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.6\u001b[39m,\n\u001b[1;32m     15\u001b[0m                     nug_mult_bounded\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     16\u001b[0m opt2 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(shrink_tm\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m)\n",
      "File \u001b[0;32m/mnt/c/PhDResearch/Self/parametricshrinkage/batram-shrink2param/src/batram/legmods.py:835\u001b[0m, in \u001b[0;36mSimpleTM.fit\u001b[0;34m(self, num_iter, init_lr, batch_size, test_data, optimizer, scheduler, stopper, silent)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_size \u001b[38;5;241m>\u001b[39m data_size:\n\u001b[1;32m    831\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    832\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatch size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is larger than data size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    833\u001b[0m     )\n\u001b[0;32m--> 835\u001b[0m losses: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m()\u001b[38;5;241m.\u001b[39mitem()]\n\u001b[1;32m    836\u001b[0m test_losses: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    837\u001b[0m     [] \u001b[38;5;28;01mif\u001b[39;00m test_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;28mself\u001b[39m(data\u001b[38;5;241m=\u001b[39mtest_data)\u001b[38;5;241m.\u001b[39mitem()]\n\u001b[1;32m    838\u001b[0m )\n\u001b[1;32m    839\u001b[0m parameters \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    840\u001b[0m     {k: np\u001b[38;5;241m.\u001b[39mcopy(v\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnamed_parameters()}\n\u001b[1;32m    841\u001b[0m ]\n",
      "File \u001b[0;32m~/miniconda3/envs/shrink2param/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/shrink2param/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/c/PhDResearch/Self/parametricshrinkage/batram-shrink2param/src/batram/legmods.py:618\u001b[0m, in \u001b[0;36mSimpleTM.forward\u001b[0;34m(self, batch_idx, data)\u001b[0m\n\u001b[1;32m    616\u001b[0m aug_data: AugmentedData \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maugment_data(data, batch_idx)\n\u001b[1;32m    617\u001b[0m nugget \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnugget(aug_data)\n\u001b[0;32m--> 618\u001b[0m kernel_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel(aug_data, nugget)\n\u001b[1;32m    619\u001b[0m intloglik \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintloglik(aug_data, kernel_result)\n\u001b[1;32m    621\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39maug_data\u001b[38;5;241m.\u001b[39mdata_size \u001b[38;5;241m/\u001b[39m aug_data\u001b[38;5;241m.\u001b[39mbatch_size \u001b[38;5;241m*\u001b[39m intloglik\u001b[38;5;241m.\u001b[39msum()\n",
      "File \u001b[0;32m~/miniconda3/envs/shrink2param/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/shrink2param/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/c/PhDResearch/Self/parametricshrinkage/batram-shrink2param/src/batram/legmods.py:376\u001b[0m, in \u001b[0;36mTransportMapKernel.forward\u001b[0;34m(self, data, nug_mean)\u001b[0m\n\u001b[1;32m    369\u001b[0m     g_chol \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mcholesky(g)\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    371\u001b[0m     \u001b[38;5;66;03m# One contrast between the errors we return here and the ones in the\u001b[39;00m\n\u001b[1;32m    372\u001b[0m     \u001b[38;5;66;03m# other function is that here we don't know which Cholesky factor\u001b[39;00m\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;66;03m# failed based on this message. It would be good to inherit the\u001b[39;00m\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;66;03m# torch.linalg.LinAlgError and make a more informative error message\u001b[39;00m\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;66;03m# with it.\u001b[39;00m\n\u001b[0;32m--> 376\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to compute Cholesky decomposition of G.\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;66;03m# Here we have talked about changing the response to be only the g\u001b[39;00m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;66;03m# matrices or simply the kernel. This requires further thought still.\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m KernelResult(g, g_chol, nug_mean)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to compute Cholesky decomposition of G."
     ]
    }
   ],
   "source": [
    "data = Data.new(torch.as_tensor(locsTrain).float(), obsTrain[0:3, :], torch.as_tensor(nn))\n",
    "\n",
    "tm = SimpleTM(data, theta_init=None, linear=False, smooth=1.5, nug_mult=4.0)\n",
    "opt = torch.optim.Adam(tm.parameters(), lr=0.01)\n",
    "sched = torch.optim.lr_scheduler.CosineAnnealingLR(opt, nsteps)\n",
    "res = tm.fit(\n",
    "    nsteps, 0.1, test_data=tm.data, optimizer=opt, scheduler=sched, batch_size=900\n",
    ")\n",
    "\n",
    "shrink_tm = EstimableShrinkTM(data=data, linear=False, \n",
    "                    transportmap_smooth=1.5, \n",
    "                    parametric_kernel= \"exponential\",\n",
    "                    param_nu=0.5,\n",
    "                    param_ls=0.6,\n",
    "                    nug_mult_bounded=False)\n",
    "opt2 = torch.optim.Adam(shrink_tm.parameters(), lr=0.01)\n",
    "sched2 = torch.optim.lr_scheduler.CosineAnnealingLR(opt2, nsteps)\n",
    "res2 = shrink_tm.fit(\n",
    "    nsteps, 0.1, test_data=shrink_tm.data, optimizer=opt2, scheduler=sched2, batch_size=2700,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "neglogScore_shrink = 0\n",
    "neglogScore_tm = 0\n",
    "for _j in range(0, 10):\n",
    "    with torch.no_grad():\n",
    "        neglogScore_tm += tm.score(obsTrain[(50 + _j), :])\n",
    "    neglogScore_shrink += shrink_tm.score(obsTrain[(50 + _j), :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-39102.6250), tensor(-32957.5469))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neglogScore_tm, neglogScore_shrink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.4907], grad_fn=<ExpBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shrink_tm.parametric_kernel.log_ls.exp()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "climate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
